{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dce686a-2b80-403a-ba16-1a3af807cfb9",
   "metadata": {},
   "source": [
    "# Creating Few-Shot and Zero-Shot Training Datasets\n",
    "\n",
    "This notebook contains the code for concatenating and shuffling (using a random seed) four out of five training sets five times for the five-shot and few times for the zero-shot scenario. For the five-shot scenario, five random samples from the \"target\" (test) dataset will be included in the concatenated training data, also using a random state for reproducibility. In the zero-shot scenario, this step will be omitted as the aim is to test the classifier trained on no samples from the test set.\n",
    "\n",
    "For the five random samples for the few-shot mixed training dataset, different random seeds will be tried to ensure there is at least one instance of every label (real/fake news) for the target samples.\n",
    "\n",
    "The \"training\" datasets concatenated here are the train splits that do *not* contain a validation split, as k-fold cross-validation will be used on the total training set to find the optimal models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71819480-2d64-4d39-a94f-9ebe56fb8129",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63cf16ec-f3df-41ef-8330-de9dec16b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle # For randomly shuffling the merged datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa3d9ceb-8be3-41cc-b964-69e235ad3e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMixedDatasetForFewShotScenario(list_of_source_train_dfs, target_df_train, number_samples=5, random_seed=5):\n",
    "    \"\"\"\n",
    "    Creates a mixed dataset for use in the few-shot evaluation scenario.\n",
    "        \n",
    "        Input Parameters:\n",
    "            list_of_source_train_dfs (list of pd.DataFrame): list of source training datasets (3 out of 4) to shuffle and concatenate\n",
    "            target_df_train (pd.DataFrame): the target dataset (that the model will be evaluted on) \n",
    "            number_samples (int): the number of samples to include from the target dataset\n",
    "            random_seed (int): the random seed for reproducibility of selecting samples from the training dataset\n",
    "        Output:\n",
    "            concat_df_shuffled (pd.DataFrame): the shuffled and merged source DataFrame to train the pipelines on in the few-shot setting\n",
    "    \"\"\"\n",
    "    \n",
    "    # Concatenates the rows of the three unimodal source datasets\n",
    "    concatenated_source_df = pd.concat(list_of_source_train_dfs, axis=0, ignore_index=True)\n",
    "    \n",
    "    # Verifies that enough samples from each label/target class are being sampled (so, a 2-3 proportion of real-fake or fake-real labels)\n",
    "    target_sample = target_df_train.sample(n=number_samples, random_state=random_seed)\n",
    "    print(\"Target sample:\\n\", target_sample[\"label\"])\n",
    "\n",
    "    # Adds the selected samples from the target dataset to the rest of the data samples as rows (axis=0) at the end of the DataFrame\n",
    "    concatenated_target_df = pd.concat([concatenated_source_df, target_sample], axis=0, ignore_index=True)\n",
    "    \n",
    "    # Applies scikit-learn's in-built shuffle function to remove ordernig from the dataset, adding a random seed for reproducibility\n",
    "    concat_df_shuffled = shuffle(concatenated_target_df, random_state=random_seed)\n",
    "\n",
    "    # Returns the merged dataset\n",
    "    return concat_df_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53b0aeef-3a67-428b-8174-79110194ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMixedDatasetForZeroShotScenario(list_of_source_train_dfs, random_seed=5):\n",
    "    \"\"\"\n",
    "    Creates a mixed dataset for use in the zero-shot evaluation scenario, as well as for creating\n",
    "    a dataset combining all the four text-only datasets to mitigate domain shift issue.\n",
    "\n",
    "    Input Parameters:\n",
    "            list_of_source_train_dfs (list of pd.DataFrame): list of source training datasets (3 out of 4) to shuffle and concatenate\n",
    "            target_df_train (pd.DataFrame): the target dataset (that the model will be evaluted on) \n",
    "            random_seed (int): the random seed for reproducibility of selecting samples from the training dataset\n",
    "\n",
    "\n",
    "    Output:\n",
    "        concat_df_shuffled (pd.DataFrame): the shuffled and merged DataFrame for training in zero-shot and all-combined evaluation scenarios\n",
    "        \n",
    "    \"\"\"\n",
    "    # Stacks the datasets vertically using axis=0\n",
    "    concatenated_source_df = pd.concat(list_of_source_train_dfs, axis=0, ignore_index=True)\n",
    "    \n",
    "    # Shuffles the combined DataFrame using sklearn's shuffle and random seed for reproducibility\n",
    "    concat_df_shuffled = shuffle(concatenated_source_df, random_state=random_seed)\n",
    "    \n",
    "    return concat_df_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "207667e4-2c9c-4650-b652-fcba9457c2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WELFake columns: Index(['id', 'title', 'text', 'label'], dtype='object')\n",
      "Fakeddit columns: Index(['author', 'clean_title', 'created_utc', 'domain', 'hasImage', 'id',\n",
      "       'image_url', 'linked_submission_id', 'num_comments', 'score',\n",
      "       'subreddit', 'text', 'upvote_ratio', 'label', '3_way_label',\n",
      "       '6_way_label'],\n",
      "      dtype='object')\n",
      "Constraint columns: Index(['id', 'text', 'label'], dtype='object')\n",
      "PolitiFact columns: Index(['id', 'text', 'label'], dtype='object')\n",
      "GossipCop columns: Index(['id', 'text', 'label'], dtype='object')\n",
      "\n",
      "\n",
      "WELFake:    original_id                                              title  \\\n",
      "0        56051  The Politics of Death: Cancer and Politics, a ...   \n",
      "1        30084  Governor-Elect Of Kentucky Tells The EPA To Go...   \n",
      "2        40781  ARE YOU READY FOR JOE? 91% Of Obama-Biden Bund...   \n",
      "3        64772  Trump win, Democratic setbacks cloud Pelosi's ...   \n",
      "4        67872  Investigators ask White House for details on F...   \n",
      "\n",
      "                                                text  label  \n",
      "0  License DMCA This is not about how politics co...      1  \n",
      "1  States have rights too! We love the new conser...      1  \n",
      "2  Bernie, Hillary and Joe a low information vote...      1  \n",
      "3  WASHINGTON (Reuters) - Nancy Pelosi may face a...      0  \n",
      "4  WASHINGTON (Reuters) - The special counsel inv...      0   \n",
      "\n",
      "\n",
      "\n",
      "Fakeddit:            author                                        clean_title  \\\n",
      "0     Alexithymia  my walgreens offbrand mucinex was engraved wit...   \n",
      "1        VIDCAs17                this concerned sink with a tiny hat   \n",
      "2  prometheus1123      hackers leak emails from uae ambassador to us   \n",
      "3             NaN                     this flower in my neighborhood   \n",
      "4             NaN                           puppy taking in the view   \n",
      "\n",
      "    created_utc         domain  hasImage original_id  \\\n",
      "0  1.551641e+09    i.imgur.com      True      awxhir   \n",
      "1  1.534727e+09      i.redd.it      True      98pbid   \n",
      "2  1.496511e+09  aljazeera.com      True      6f2cy5   \n",
      "3  1.557764e+09      i.redd.it     False      bo5i67   \n",
      "4  1.471341e+09    i.imgur.com      True      4xypkv   \n",
      "\n",
      "                                           image_url linked_submission_id  \\\n",
      "0  https://external-preview.redd.it/WylDbZrnbvZdB...                  NaN   \n",
      "1  https://preview.redd.it/wsfx0gp0f5h11.jpg?widt...                  NaN   \n",
      "2  https://external-preview.redd.it/6fNhdbc6K1vFA...                  NaN   \n",
      "3                                                NaN                  NaN   \n",
      "4  https://external-preview.redd.it/HLtVNhTR6wtYt...                  NaN   \n",
      "\n",
      "   num_comments  score          subreddit  \\\n",
      "0           2.0     12  mildlyinteresting   \n",
      "1           2.0    119         pareidolia   \n",
      "2           1.0     44        neutralnews   \n",
      "3           0.0     17  mildlyinteresting   \n",
      "4          26.0    250   photoshopbattles   \n",
      "\n",
      "                                                text  upvote_ratio  label  \\\n",
      "0  My Walgreens offbrand Mucinex was engraved wit...          0.84      0   \n",
      "1                This concerned sink with a tiny hat          0.99      1   \n",
      "2      Hackers leak emails from UAE ambassador to US          0.92      0   \n",
      "3                     This flower in my neighborhood          0.92      0   \n",
      "4                 PsBattle: Puppy taking in the view          0.95      0   \n",
      "\n",
      "   3_way_label  6_way_label  \n",
      "0            0            0  \n",
      "1            2            2  \n",
      "2            0            0  \n",
      "3            0            0  \n",
      "4            0            0   \n",
      "\n",
      "\n",
      "\n",
      "Constraint:    original_id                                               text  label\n",
      "0            1  The CDC currently reports 99031 deaths. In gen...      0\n",
      "1            2  States reported 1121 deaths a small rise from ...      0\n",
      "2            3  Politically Correct Woman (Almost) Uses Pandem...      1\n",
      "3            4  #IndiaFightsCorona: We have 1524 #COVID testin...      0\n",
      "4            5  Populous states can generate large case counts...      0 \n",
      "\n",
      "\n",
      "\n",
      "PolitiFact:        original_id                                               text  label\n",
      "0    politifact462  Return to Transcripts main page\\n\\nAMERICAN MO...      0\n",
      "1   politifact8557  The award-winning, nonpartisan intel you can t...      0\n",
      "2  politifact15280  DraftKings Named Exclusive Odds Provider For A...      1\n",
      "3  politifact14905  The guest list hasn’t been set for the royal w...      1\n",
      "4   politifact1067  This is a rush transcript from \"On the Record,...      0 \n",
      "\n",
      "\n",
      "\n",
      "GossipCop:             original_id                                               text  \\\n",
      "0      gossipcop-871425  American news and talk television show\\n\\nToda...   \n",
      "1  gossipcop-9574358029  Angelina Jolie attends First They Killed My Fa...   \n",
      "2  gossipcop-1587930811  Now that Katie Holmes & Jamie Foxx’s relations...   \n",
      "3      gossipcop-890268  THE race is on to become the next Christmas Nu...   \n",
      "4      gossipcop-924667  As Meghan Markle prepares to officially enter ...   \n",
      "\n",
      "   label  \n",
      "0      0  \n",
      "1      1  \n",
      "2      1  \n",
      "3      0  \n",
      "4      0   \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sets up all the paths to access the different training datasets\n",
    "\n",
    "\n",
    "# WELFake\n",
    "wf_path = \"../../FPData/WELFake/\"\n",
    "train_path_wf = os.path.join(wf_path, \"clean_train_wf.csv\") # \"clean\" means dataset has simply been cleaned of NaNs and duplicates\n",
    "# Fakeddit\n",
    "fe_path = \"../../FPData/Fakeddit/\"\n",
    "train_path_fe = os.path.join(fe_path, \"clean_train.csv\")\n",
    "# Constraint\n",
    "ct_path = \"../../FPData/Constraint/\"\n",
    "train_path_ct = os.path.join(ct_path, \"clean_train.csv\")\n",
    "# PolitiFact\n",
    "pf_path = \"../../FPData/PolitiFact/\"\n",
    "train_path_pf = os.path.join(pf_path, \"clean_train_pf.csv\")\n",
    "# GossipCop\n",
    "gc_path = \"../../FPData/GossipCop/\"\n",
    "train_path_gc = os.path.join(gc_path, \"clean_train_gc.csv\")\n",
    "\n",
    "# Prints the column names for all datasets\n",
    "wf_df = pd.read_csv(train_path_wf)\n",
    "print(f\"WELFake columns: {wf_df.columns}\")\n",
    "fe_df = pd.read_csv(train_path_fe)\n",
    "print(f\"Fakeddit columns: {fe_df.columns}\")\n",
    "ct_df = pd.read_csv(train_path_ct)\n",
    "print(f\"Constraint columns: {ct_df.columns}\")\n",
    "pf_df = pd.read_csv(train_path_pf)\n",
    "print(f\"PolitiFact columns: {pf_df.columns}\")\n",
    "gc_df = pd.read_csv(train_path_gc)\n",
    "print(f\"GossipCop columns: {gc_df.columns}\")\n",
    "\n",
    "# Renames the id columns to \"original_id\" to keep track of the original \"source\" dataset\n",
    "wf_df = wf_df.rename(columns={\"id\": \"original_id\"})\n",
    "fe_df = fe_df.rename(columns={\"id\": \"original_id\"})\n",
    "ct_df = ct_df.rename(columns={\"id\": \"original_id\"})\n",
    "pf_df = pf_df.rename(columns={\"id\": \"original_id\"})\n",
    "gc_df = gc_df.rename(columns={\"id\": \"original_id\"})\n",
    "\n",
    "# Checks it has worked\n",
    "print(\"\\n\\nWELFake:\", wf_df.head(), \"\\n\\n\\n\")\n",
    "print(\"Fakeddit:\", fe_df.head(), \"\\n\\n\\n\")\n",
    "print(\"Constraint:\", ct_df.head(), \"\\n\\n\\n\")\n",
    "print(\"PolitiFact:\", pf_df.head(), \"\\n\\n\\n\")\n",
    "print(\"GossipCop:\", gc_df.head(), \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b541edb9-9890-4542-abed-c984d4edd2bc",
   "metadata": {},
   "source": [
    "## Preprocessing Datasets to Get the Same Columns and Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b6bbdb4-7094-4b1c-b39c-2089a6186c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            original_id                                               text  \\\n",
      "0      gossipcop-871425  American news and talk television show\\n\\nToda...   \n",
      "1  gossipcop-9574358029  Angelina Jolie attends First They Killed My Fa...   \n",
      "2  gossipcop-1587930811  Now that Katie Holmes & Jamie Foxx’s relations...   \n",
      "3      gossipcop-890268  THE race is on to become the next Christmas Nu...   \n",
      "4      gossipcop-924667  As Meghan Markle prepares to officially enter ...   \n",
      "\n",
      "   label  hasImage  \n",
      "0      0     False  \n",
      "1      1     False  \n",
      "2      1     False  \n",
      "3      0     False  \n",
      "4      0     False  \n",
      "            original_id                                               text  \\\n",
      "0      gossipcop-871425  American news and talk television show\\n\\nToda...   \n",
      "1  gossipcop-9574358029  Angelina Jolie attends First They Killed My Fa...   \n",
      "2  gossipcop-1587930811  Now that Katie Holmes & Jamie Foxx’s relations...   \n",
      "3      gossipcop-890268  THE race is on to become the next Christmas Nu...   \n",
      "4      gossipcop-924667  As Meghan Markle prepares to officially enter ...   \n",
      "\n",
      "   label  hasImage  image_url  \n",
      "0      0     False        NaN  \n",
      "1      1     False        NaN  \n",
      "2      1     False        NaN  \n",
      "3      0     False        NaN  \n",
      "4      0     False        NaN  \n",
      "            original_id                                               text  \\\n",
      "0      gossipcop-871425  American news and talk television show\\n\\nToda...   \n",
      "1  gossipcop-9574358029  Angelina Jolie attends First They Killed My Fa...   \n",
      "2  gossipcop-1587930811  Now that Katie Holmes & Jamie Foxx’s relations...   \n",
      "3      gossipcop-890268  THE race is on to become the next Christmas Nu...   \n",
      "4      gossipcop-924667  As Meghan Markle prepares to officially enter ...   \n",
      "\n",
      "   label  hasImage  image_url original_dataset  \n",
      "0      0     False        NaN        GossipCop  \n",
      "1      1     False        NaN        GossipCop  \n",
      "2      1     False        NaN        GossipCop  \n",
      "3      0     False        NaN        GossipCop  \n",
      "4      0     False        NaN        GossipCop  \n",
      "\n",
      "\n",
      " Index(['original_id', 'text', 'label', 'hasImage', 'image_url',\n",
      "       'original_dataset'],\n",
      "      dtype='object') \n",
      " Index(['original_id', 'text', 'label', 'hasImage', 'image_url',\n",
      "       'original_dataset'],\n",
      "      dtype='object') \n",
      " Index(['original_id', 'text', 'label', 'hasImage', 'image_url',\n",
      "       'original_dataset'],\n",
      "      dtype='object') \n",
      " Index(['original_id', 'text', 'label', 'hasImage', 'image_url',\n",
      "       'original_dataset'],\n",
      "      dtype='object') \n",
      " Index(['original_id', 'text', 'label', 'hasImage', 'image_url',\n",
      "       'original_dataset'],\n",
      "      dtype='object') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adds the hasImage column to all datasets except Fakeddit, which already has one, and set values to False for all other dataframes\n",
    "wf_df[\"hasImage\"] = False\n",
    "ct_df[\"hasImage\"] = False\n",
    "pf_df[\"hasImage\"] = False\n",
    "gc_df[\"hasImage\"] = False\n",
    "\n",
    "# Checks it has worked\n",
    "print(gc_df.head())\n",
    "\n",
    "# Adds the image_url column to all non-image non-multimodal datasets (all except Fakeddit which has image URLs) and set values to np.NaN\n",
    "wf_df[\"image_url\"] = np.NaN\n",
    "ct_df[\"image_url\"] = np.NaN\n",
    "pf_df[\"image_url\"] = np.NaN\n",
    "gc_df[\"image_url\"] = np.NaN\n",
    "# Check it has worked\n",
    "print(gc_df.head())\n",
    "\n",
    "# Adds a column in each dataset to mark the original dataset the news sample came from\n",
    "wf_df[\"original_dataset\"] = \"WELFake\"\n",
    "fe_df[\"original_dataset\"] = \"Fakeddit\"\n",
    "ct_df[\"original_dataset\"] = \"Constraint\"\n",
    "pf_df[\"original_dataset\"] = \"PolitiFact\"\n",
    "gc_df[\"original_dataset\"] = \"GossipCop\"\n",
    "# Check it has worked\n",
    "print(gc_df.head())\n",
    "\n",
    "# Makes sure columns are the same in each DataFrame\n",
    "wf_df_cols = wf_df[[\"original_id\", \"text\", \"label\", \"hasImage\", \"image_url\", \"original_dataset\"]]\n",
    "fe_df_cols = fe_df[[\"original_id\", \"text\", \"label\", \"hasImage\", \"image_url\", \"original_dataset\"]]\n",
    "ct_df_cols = ct_df[[\"original_id\", \"text\", \"label\", \"hasImage\", \"image_url\", \"original_dataset\"]]\n",
    "pf_df_cols = pf_df[[\"original_id\", \"text\", \"label\", \"hasImage\", \"image_url\", \"original_dataset\"]]\n",
    "gc_df_cols = gc_df[[\"original_id\", \"text\", \"label\", \"hasImage\", \"image_url\", \"original_dataset\"]]\n",
    "\n",
    "# Check it has worked\n",
    "print(\"\\n\\n\", wf_df_cols.columns, \"\\n\", fe_df_cols.columns, \"\\n\", ct_df_cols.columns, \"\\n\", pf_df_cols.columns, \"\\n\", \n",
    "     gc_df_cols.columns, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fc402c-840a-4729-9515-40f42c35a0c9",
   "metadata": {},
   "source": [
    "## Concatenating the Five-Shot DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ce4471-b76f-4a85-affd-c8a63c508082",
   "metadata": {},
   "source": [
    "### Five-Shot Datasets (including Fakeddit multimodal dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35306766-4a76-4417-922b-cdba3db78385",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Fakeddit has been excluded following the Data Analysis\n",
    "\n",
    "# five_shot_all_except_welfake = createMixedDatasetForFewShotScenario(\n",
    "#     [fe_df_cols, ct_df_cols, pf_df_cols, gc_df_cols], \n",
    "#     # changed the random seed from default 5 to 10 due to some classes being missing from the 5 random rows, need a 2-3 balance\n",
    "#     wf_df_cols, number_samples=5, random_seed=10 \n",
    "# )\n",
    "\n",
    "# five_shot_all_except_fakeddit = createMixedDatasetForFewShotScenario(\n",
    "#     [wf_df_cols, ct_df_cols, pf_df_cols, gc_df_cols], \n",
    "#     fe_df_cols, number_samples=5, random_seed=5\n",
    "# )\n",
    "\n",
    "# five_shot_all_except_constraint = createMixedDatasetForFewShotScenario(\n",
    "#     [wf_df_cols, fe_df_cols, pf_df_cols, gc_df_cols], \n",
    "#     ct_df_cols, number_samples=5, random_seed=5\n",
    "# )\n",
    "\n",
    "# five_shot_all_except_politifact = createMixedDatasetForFewShotScenario(\n",
    "#     [wf_df_cols, fe_df_cols, ct_df_cols, gc_df_cols], \n",
    "#     pf_df_cols, number_samples=5, random_seed=5\n",
    "# )\n",
    "\n",
    "# five_shot_all_except_gossipcop = createMixedDatasetForFewShotScenario(\n",
    "#     [wf_df_cols, fe_df_cols, ct_df_cols, pf_df_cols], \n",
    "#     gc_df_cols, number_samples=5, random_seed=7 # changed random seed from 5 to 7 due to some labels being missing, need a 2-3 balance\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5b5469-8cc8-40f7-a83a-7934b1a89ca0",
   "metadata": {},
   "source": [
    "### Five-Shot Datasets (excluding Fakeddit multimodal dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c08423a1-5a28-4625-b9e0-ad59ec2cbad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_fakeddit_five_shot_target_welfake = createMixedDatasetForFewShotScenario(\n",
    "    [ct_df_cols, pf_df_cols, gc_df_cols], \n",
    "    wf_df_cols, number_samples=5, random_seed=10 # Experiment with different random seeds until get labels from both classes\n",
    ")\n",
    "\n",
    "no_fakeddit_five_shot_target_constraint = createMixedDatasetForFewShotScenario(\n",
    "    [wf_df_cols, pf_df_cols, gc_df_cols], \n",
    "    ct_df_cols, number_samples=5, random_seed=9\n",
    ")\n",
    "\n",
    "no_fakeddit_five_shot_target_politifact = createMixedDatasetForFewShotScenario(\n",
    "    [wf_df_cols, ct_df_cols, gc_df_cols], \n",
    "    pf_df_cols, number_samples=5, random_seed=5\n",
    ")\n",
    "\n",
    "no_fakeddit_five_shot_target_gossipcop = createMixedDatasetForFewShotScenario(\n",
    "    [wf_df_cols, ct_df_cols, pf_df_cols], \n",
    "    gc_df_cols, number_samples=5, random_seed=20 # changed random seed from 5 to 20 due to some labels being missing, need a 2-3 balance\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cf59bcb-4904-47f1-88c8-791ec6fb5eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropDuplicates(df, dataset_name):\n",
    "    \"\"\"\n",
    "        A function which removes duplicate rows based on duplication in the \"text\" field\n",
    "        for a news dataset and prints the number of duplicates that were removed.\n",
    "\n",
    "        Input Parameters:\n",
    "            df (pd.DataFrame): the news DataFrame (with a \"text\" field) to clean duplicates from\n",
    "            name (str): name of the dataset for logging results of duplicate removal\n",
    "\n",
    "        Output:\n",
    "            df_no_duplicates (pd.DataFrame): the news DataFrame with duplicate \"text\" entries removed\n",
    "    \"\"\"\n",
    "    # Prints the original number of rows in the DataFrame\n",
    "    original_len = len(df)\n",
    "    \n",
    "    # Drops the duplicates based on the \"text\" column, keeping the first occurrence only\n",
    "    df_no_duplicates = df.drop_duplicates(subset=[\"text\"], keep=\"first\")\n",
    "    \n",
    "    # Return the modified DataFrame with duplicates removed\n",
    "    return df_no_duplicates\n",
    "\n",
    "# Apply the drop duplicates function to each of the datasets\n",
    "five_shot_all_except_welfake_no_duplicates = dropDuplicates(five_shot_all_except_welfake, \"five_shot_all_except_welfake\")\n",
    "five_shot_all_except_fakeddit_no_duplicates = dropDuplicates(five_shot_all_except_fakeddit, \"five_shot_all_except_fakeddit\")\n",
    "five_shot_all_except_constraint_no_duplicates = dropDuplicates(five_shot_all_except_constraint, \"five_shot_all_except_constraint\")\n",
    "five_shot_all_except_politifact_no_duplicates = dropDuplicates(five_shot_all_except_politifact, \"five_shot_all_except_politifact\")\n",
    "five_shot_all_except_gossipcop_no_duplicates = dropDuplicates(five_shot_all_except_gossipcop, \"five_shot_all_except_gossipcop\")\n",
    "\n",
    "\n",
    "# Applies the function to the five-shot datasets excluding Fakeddit\n",
    "no_fakeddit_five_shot_target_welfake_no_duplicates = dropDuplicates(no_fakeddit_five_shot_target_welfake,\n",
    "                                                                    \"no_fakeddit_five_shot_all_except_welfake\")\n",
    "no_fakeddit_five_shot_target_constraint_no_duplicates = dropDuplicates(no_fakeddit_five_shot_target_constraint,\n",
    "                                                                    \"no_fakeddit_five_shot_all_except_constraint\")\n",
    "no_fakeddit_five_shot_target_politifact_no_duplicates = dropDuplicates(no_fakeddit_five_shot_target_politifact,\n",
    "                                                                    \"no_fakeddit_five_shot_all_except_politifact\")\n",
    "no_fakeddit_five_shot_target_gossipcop_no_duplicates = dropDuplicates(no_fakeddit_five_shot_target_gossipcop,\n",
    "                                                                    \"no_fakeddit_five_shot_all_except_gossipcop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e251379f-6209-42c1-8263-3e7e6a3c7c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48124    PolitiFact\n",
      "54051     GossipCop\n",
      "4697        WELFake\n",
      "2620        WELFake\n",
      "25101       WELFake\n",
      "3952        WELFake\n",
      "26494       WELFake\n",
      "43136    Constraint\n",
      "37609       WELFake\n",
      "10491       WELFake\n",
      "49106     GossipCop\n",
      "17301       WELFake\n",
      "23098       WELFake\n",
      "32259       WELFake\n",
      "20676       WELFake\n",
      "6597        WELFake\n",
      "34360       WELFake\n",
      "24056       WELFake\n",
      "40604       WELFake\n",
      "31978       WELFake\n",
      "33555       WELFake\n",
      "31599       WELFake\n",
      "36044       WELFake\n",
      "3564        WELFake\n",
      "37756       WELFake\n",
      "57491     GossipCop\n",
      "51303     GossipCop\n",
      "97          WELFake\n",
      "9438        WELFake\n",
      "51368     GossipCop\n",
      "Name: original_dataset, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if datasets are shuffled properly by taking a slice and step through the data\n",
    "print(five_shot_all_except_fakeddit_no_duplicates[\"original_dataset\"].iloc[1000:10000:300], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cef2f1de-6012-41a8-aca4-589c2dd0c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saves the new training datasets\n",
    "def saveFewShotDataset(few_shot_df, target_dataset_name):\n",
    "    \"\"\"\n",
    "    Saves the mixed few/five-shot dataset with Fakeddit.\n",
    "        \n",
    "        Input Parameters:\n",
    "            few_shot_df (pd.DataFrame): the combined training dataset to save\n",
    "            target_dataset_name(str): the name of the target dataset\n",
    "    \"\"\"\n",
    "    save_path =  f\"../FPData/CleanFewShotDatasets_withoutValSets/five_shot_train_data_except_{target_dataset_name}.csv\"\n",
    "    few_shot_df.to_csv(save_path, index=False)\n",
    "\n",
    "saveFewShotDataset(five_shot_all_except_welfake_no_duplicates, \"welfake\")\n",
    "saveFewShotDataset(five_shot_all_except_fakeddit_no_duplicates , \"fakeddit\")\n",
    "saveFewShotDataset(five_shot_all_except_constraint_no_duplicates , \"constraint\")\n",
    "saveFewShotDataset(five_shot_all_except_politifact_no_duplicates , \"politifact\")\n",
    "saveFewShotDataset(five_shot_all_except_constraint_no_duplicates , \"gossipcop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6eea2bf0-21be-4327-8492-e5de7816f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveFewShotDatasetWithoutFakeddit(few_shot_df, target_dataset_name,\n",
    "                                      root_path=\"../FPData/CleanFewShotDatasets_withoutValSets_withoutFakeddit\"):\n",
    "    \"\"\"\n",
    "    Saves the mixed few/five-shot dataset without Fakeddit.\n",
    "        \n",
    "        Input Parameters:\n",
    "            few_shot_df (pd.DataFrame): the combined training dataset to save\n",
    "            target_dataset_name(str): the name of the target dataset\n",
    "            root_path (str): the name of the directory to save the .csv file to\n",
    "    \"\"\"\n",
    "    save_path =  f\"{os.path.join(root_path, target_dataset_name)}.csv\"\n",
    "    few_shot_df.to_csv(save_path, index=False)\n",
    "    \n",
    "saveFewShotDatasetWithoutFakeddit(no_fakeddit_five_shot_target_welfake_no_duplicates, \"five_shot_train_data_except_welfake\")\n",
    "saveFewShotDatasetWithoutFakeddit(no_fakeddit_five_shot_target_constraint_no_duplicates, \"five_shot_train_data_except_constraint\")\n",
    "saveFewShotDatasetWithoutFakeddit(no_fakeddit_five_shot_target_politifact_no_duplicates, \"five_shot_train_data_except_politifact\")\n",
    "saveFewShotDatasetWithoutFakeddit(no_fakeddit_five_shot_target_gossipcop_no_duplicates, \"five_shot_train_data_except_gossipcop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14916bd5-9e92-442c-be49-c5fff97dc1f4",
   "metadata": {},
   "source": [
    "## Concatenating the Zero-Shot DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a88f9e7-637b-4d9e-bc02-1179ab88509f",
   "metadata": {},
   "source": [
    "### Zero-Shot Datasets: With Fakeddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7db8ff84-0895-45a0-aa6e-a172cfd01320",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fakeddit has been excluded now following data analysis\n",
    "\n",
    "# zero_shot_all_except_welfake = createMixedDatasetForZeroShotScenario(\n",
    "#     [fe_df_cols, ct_df_cols, pf_df_cols, gc_df_cols]\n",
    "# )\n",
    "\n",
    "# zero_shot_all_except_fakeddit = createMixedDatasetForZeroShotScenario(\n",
    "#     [wf_df_cols, ct_df_cols, pf_df_cols, gc_df_cols]\n",
    "# )\n",
    "\n",
    "# zero_shot_all_except_constraint = createMixedDatasetForZeroShotScenario(\n",
    "#     [wf_df_cols, fe_df_cols, pf_df_cols, gc_df_cols]\n",
    "# )\n",
    "\n",
    "# zero_shot_all_except_politifact = createMixedDatasetForZeroShotScenario(\n",
    "#     [wf_df_cols, fe_df_cols, ct_df_cols, gc_df_cols]\n",
    "# )\n",
    "\n",
    "# zero_shot_all_except_gossipcop = createMixedDatasetForZeroShotScenario(\n",
    "#     [wf_df_cols, fe_df_cols, ct_df_cols, pf_df_cols]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d912b1a-73f5-411b-83bf-301c9258e80e",
   "metadata": {},
   "source": [
    "### Zero-Shot Datasets: Without Fakeddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3d483e77-cb66-4a11-9527-f88f243c452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creates the mixed datasets without Fakeddit\n",
    "\n",
    "# no_fakeddit_zero_shot_all_except_welfake = createMixedDatasetForZeroShotScenario(\n",
    "#     [ct_df_cols, pf_df_cols, gc_df_cols]\n",
    "# )\n",
    "\n",
    "# no_fakeddit_zero_shot_all_except_constraint = createMixedDatasetForZeroShotScenario(\n",
    "#     [wf_df_cols, pf_df_cols, gc_df_cols]\n",
    "# )\n",
    "\n",
    "# no_fakeddit_zero_shot_all_except_politifact = createMixedDatasetForZeroShotScenario(\n",
    "#     [wf_df_cols, ct_df_cols, gc_df_cols]\n",
    "# )\n",
    "\n",
    "# no_fakeddit_zero_shot_all_except_gossipcop = createMixedDatasetForZeroShotScenario(\n",
    "#     [wf_df_cols, ct_df_cols, pf_df_cols]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3fa95ba5-41f7-4bdc-8711-eb1e68e6eae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For zero_shot_all_except_welfake, 2 duplicate rows were removed.\n",
      "For zero_shot_all_except_fakeddit, 2 duplicate rows were removed.\n",
      "For zero_shot_all_except_constraint, 2 duplicate rows were removed.\n",
      "For zero_shot_all_except_politifact, 0 duplicate rows were removed.\n",
      "For zero_shot_all_except_gossipcop, 0 duplicate rows were removed.\n"
     ]
    }
   ],
   "source": [
    "# Applies the drop duplicates function to each of the Fakeddit-including zero-shot datasets\n",
    "zero_shot_all_except_welfake_no_duplicates = dropDuplicates(zero_shot_all_except_welfake, \"zero_shot_all_except_welfake\")\n",
    "zero_shot_all_except_fakeddit_no_duplicates = dropDuplicates(zero_shot_all_except_fakeddit, \"zero_shot_all_except_fakeddit\")\n",
    "zero_shot_all_except_constraint_no_duplicates = dropDuplicates(zero_shot_all_except_constraint, \"zero_shot_all_except_constraint\")\n",
    "zero_shot_all_except_politifact_no_duplicates = dropDuplicates(zero_shot_all_except_politifact, \"zero_shot_all_except_politifact\")\n",
    "zero_shot_all_except_gossipcop_no_duplicates = dropDuplicates(zero_shot_all_except_gossipcop, \"zero_shot_all_except_gossipcop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "144b1984-9ca8-4609-ba0d-facb1af84899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For no_fakeddit_zero_shot_all_except_welfake, 2 duplicate rows were removed.\n",
      "For no_fakeddit_zero_shot_all_except_constraint, 2 duplicate rows were removed.\n",
      "For no_fakeddit_zero_shot_all_except_politifact, 0 duplicate rows were removed.\n",
      "For no_fakeddit_zero_shot_all_except_gossipcop, 0 duplicate rows were removed.\n"
     ]
    }
   ],
   "source": [
    "# Applies the drop duplicates function to each of the zero-shot no-Fakeddit datasets\n",
    "no_fakeddit_zero_shot_all_except_welfake_no_duplicates = dropDuplicates(\n",
    "    no_fakeddit_zero_shot_all_except_welfake,\n",
    "    \"no_fakeddit_zero_shot_all_except_welfake\"\n",
    ")\n",
    "no_fakeddit_zero_shot_all_except_constraint_no_duplicates = dropDuplicates(\n",
    "    no_fakeddit_zero_shot_all_except_constraint,\n",
    "    \"no_fakeddit_zero_shot_all_except_constraint\"\n",
    ")\n",
    "no_fakeddit_zero_shot_all_except_politifact_no_duplicates = dropDuplicates(\n",
    "    no_fakeddit_zero_shot_all_except_politifact,\n",
    "    \"no_fakeddit_zero_shot_all_except_politifact\"\n",
    ")\n",
    "no_fakeddit_zero_shot_all_except_gossipcop_no_duplicates = dropDuplicates(\n",
    "    no_fakeddit_zero_shot_all_except_gossipcop,\n",
    "    \"no_fakeddit_zero_shot_all_except_gossipcop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "31e10742-c75f-41ed-862a-4ab68a41462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveZeroShotDataset(zero_shot_df, target_dataset_name):\n",
    "    \"\"\"\n",
    "    Saves the mixed zero-shot dataset with Fakeddit.\n",
    "        \n",
    "        Input Parameters:\n",
    "            zero_shot_df (pd.DataFrame): the combined training dataset to save\n",
    "            target_dataset_name(str): the name of the target dataset\n",
    "    \"\"\"\n",
    "    save_path =  f\"../FPData/CleanZeroShotDatasets_withoutValSets/zero_shot_train_data_except_{target_dataset_name}.csv\"\n",
    "    zero_shot_df.to_csv(save_path, index=False)\n",
    "\n",
    "saveZeroShotDataset(zero_shot_all_except_welfake_no_duplicates, \"welfake\")\n",
    "saveZeroShotDataset(zero_shot_all_except_fakeddit_no_duplicates, \"fakeddit\")\n",
    "saveZeroShotDataset(zero_shot_all_except_constraint_no_duplicates, \"constraint\")\n",
    "saveZeroShotDataset(zero_shot_all_except_politifact_no_duplicates, \"politifact\")\n",
    "saveZeroShotDataset(zero_shot_all_except_gossipcop_no_duplicates, \"gossipcop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2269d56b-be3b-40b4-b394-82b38809995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the new combined training datasets without Fakeddit\n",
    "def saveZeroShotDatasetWithoutFakeddit(zero_shot_df, target_dataset_name,\n",
    "                                      root_path=\"../FPData/CleanZeroShotDatasets_withoutValSets_withoutFakeddit\"):\n",
    "    \"\"\"\n",
    "    Saves the mixed zero-shot dataset without Fakeddit.\n",
    "        \n",
    "        Input Parameters:\n",
    "            few_shot_df (pd.DataFrame): the combined training dataset to save\n",
    "            target_dataset_name(str): the name of the target dataset\n",
    "            root_path (str): the name of the directory to save the .csv file to\n",
    "    \"\"\"\n",
    "    save_path =  f\"{os.path.join(root_path, target_dataset_name)}.csv\"\n",
    "    zero_shot_df.to_csv(save_path, index=False)\n",
    "    \n",
    "saveZeroShotDatasetWithoutFakeddit(no_fakeddit_zero_shot_all_except_welfake_no_duplicates, \"zero_shot_train_data_except_welfake\")\n",
    "saveZeroShotDatasetWithoutFakeddit(no_fakeddit_zero_shot_all_except_constraint_no_duplicates, \"zero_shot_train_data_except_constraint\")\n",
    "saveZeroShotDatasetWithoutFakeddit(no_fakeddit_zero_shot_all_except_politifact_no_duplicates, \"zero_shot_train_data_except_politifact\")\n",
    "saveZeroShotDatasetWithoutFakeddit(no_fakeddit_zero_shot_all_except_gossipcop_no_duplicates, \"zero_shot_train_data_except_gossipcop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baadae9d-35f9-4ea9-a503-a139cd825d6c",
   "metadata": {},
   "source": [
    "## Creating the All-Four combined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1a02cab7-5f79-4725-82ca-8101145193e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dataset of all source (text-only, excluding Fakeddit) datasets for training the model for user testing on ALL data\n",
    "all_train_data = createMixedDatasetForZeroShotScenario(\n",
    "    [wf_df_cols, ct_df_cols, pf_df_cols, gc_df_cols]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c4859706-4234-40b3-9100-d90132ae9ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GossipCop', 'WELFake', 'PolitiFact', 'Constraint'], dtype=object)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks the 4 datasets are in there, no Fakeddit\n",
    "all_train_data[\"original_dataset\"].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "97fee9a8-c535-46cc-a8a1-2c2a69ace8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the all_train dataset\n",
    "all_train_data.to_csv(\"../FPData/four_training_sets_combined.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2689cdc7-3d65-459c-a302-839bc8cb9d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads in and combines the validation sets and test sets for evaluating on all 4 text-based datasets combined\n",
    "\n",
    "# WELFake\n",
    "val_path_wf = os.path.join(wf_path, \"clean_val_wf.csv\")\n",
    "wf_val_df = pd.read_csv(val_path_wf)\n",
    "test_path_wf = os.path.join(wf_path, \"clean_test_wf.csv\")\n",
    "wf_test_df = pd.read_csv(test_path_wf)\n",
    "\n",
    "# Constraint\n",
    "val_path_ct = os.path.join(ct_path, \"clean_val.csv\")\n",
    "ct_val_df = pd.read_csv(val_path_ct)\n",
    "test_path_ct = os.path.join(ct_path, \"clean_test.csv\")\n",
    "ct_test_df = pd.read_csv(test_path_ct)\n",
    "\n",
    "# PolitiFact\n",
    "val_path_pf = os.path.join(pf_path, \"clean_val_pf.csv\")\n",
    "pf_val_df = pd.read_csv(val_path_pf)\n",
    "test_path_pf = os.path.join(pf_path, \"clean_test_pf.csv\")\n",
    "pf_test_df = pd.read_csv(test_path_pf)\n",
    "\n",
    "# GossipCop\n",
    "val_path_gc = os.path.join(gc_path, \"clean_val_gc.csv\")\n",
    "gc_val_df = pd.read_csv(val_path_gc)\n",
    "test_path_gc = os.path.join(gc_path, \"clean_test_gc.csv\")\n",
    "gc_test_df = pd.read_csv(test_path_gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e8847b59-9142-413a-8eed-7d3436c1c235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64425</td>\n",
       "      <td>Chilean economic officials resign in blow to c...</td>\n",
       "      <td>SANTIAGO (Reuters) - Chilean President Michell...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46016</td>\n",
       "      <td>Nintendo Switch Won’t Support Video Streaming ...</td>\n",
       "      <td>A few more details have dribbled out about the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1496</td>\n",
       "      <td>Obama hits the trail for Hillary Clinton: Will...</td>\n",
       "      <td>President Obama campaigns Tuesday with Mrs. Cl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27368</td>\n",
       "      <td>President Elect Trump – A New Era of Unpredict...</td>\n",
       "      <td>Waking Times \\nPresident Elect Trump is new ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66323</td>\n",
       "      <td>Turkish academic on lengthy hunger strike appe...</td>\n",
       "      <td>ANKARA (Reuters) - A sacked Turkish professor ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0  64425  Chilean economic officials resign in blow to c...   \n",
       "1  46016  Nintendo Switch Won’t Support Video Streaming ...   \n",
       "2   1496  Obama hits the trail for Hillary Clinton: Will...   \n",
       "3  27368  President Elect Trump – A New Era of Unpredict...   \n",
       "4  66323  Turkish academic on lengthy hunger strike appe...   \n",
       "\n",
       "                                                text  label  \n",
       "0  SANTIAGO (Reuters) - Chilean President Michell...      0  \n",
       "1  A few more details have dribbled out about the...      0  \n",
       "2  President Obama campaigns Tuesday with Mrs. Cl...      0  \n",
       "3  Waking Times \\nPresident Elect Trump is new ti...      1  \n",
       "4  ANKARA (Reuters) - A sacked Turkish professor ...      0  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drops the unwanted \"Unnamed\" column from the WELFake validation set\n",
    "wf_val_df = wf_val_df.drop(\"Unnamed: 0\", axis=1) \n",
    "wf_val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e77c3a7e-fd72-4f8f-866b-d49d47082c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12113</td>\n",
       "      <td>WTF: Top Trump Advisor Tells Trump To Kill Li...</td>\n",
       "      <td>As if Donald Trump isn t paranoid and delusion...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65434</td>\n",
       "      <td>EU leaders to give mandate for next phase of B...</td>\n",
       "      <td>BRUSSELS (Reuters) - European Union leaders wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42045</td>\n",
       "      <td>If this is what a “Rubio surge” looks like, Re...</td>\n",
       "      <td>On one hand, it is yet another example of how ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50226</td>\n",
       "      <td>Morneau Shepell​ sees no impact from pension l...</td>\n",
       "      <td>OTTAWA (Reuters) - Morneau Shepell Inc (MSI.TO...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8925</td>\n",
       "      <td>Trump touts support for NATO, but expansion la...</td>\n",
       "      <td>WASHINGTON(Reuters) - In his first major speec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0  12113   WTF: Top Trump Advisor Tells Trump To Kill Li...   \n",
       "1  65434  EU leaders to give mandate for next phase of B...   \n",
       "2  42045  If this is what a “Rubio surge” looks like, Re...   \n",
       "3  50226  Morneau Shepell​ sees no impact from pension l...   \n",
       "4   8925  Trump touts support for NATO, but expansion la...   \n",
       "\n",
       "                                                text  label  \n",
       "0  As if Donald Trump isn t paranoid and delusion...      1  \n",
       "1  BRUSSELS (Reuters) - European Union leaders wi...      0  \n",
       "2  On one hand, it is yet another example of how ...      0  \n",
       "3  OTTAWA (Reuters) - Morneau Shepell Inc (MSI.TO...      0  \n",
       "4  WASHINGTON(Reuters) - In his first major speec...      0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drops the unwanted \"Unnamed\" column from the WELFake test set\n",
    "wf_test_df = wf_test_df.drop(\"Unnamed: 0\", axis=1)\n",
    "wf_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c2ce9691-cc6c-43f9-bfaa-e23c676b29b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Chinese converting to Islam after realising th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11 out of 13 people (from the Diamond Princess...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>COVID-19 Is Caused By A Bacterium, Not Virus A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mike Pence in RNC speech praises Donald Trump’...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6/10 Sky's @EdConwaySky explains the latest #C...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  label\n",
       "0   1  Chinese converting to Islam after realising th...      1\n",
       "1   2  11 out of 13 people (from the Diamond Princess...      1\n",
       "2   3  COVID-19 Is Caused By A Bacterium, Not Virus A...      1\n",
       "3   4  Mike Pence in RNC speech praises Donald Trump’...      1\n",
       "4   5  6/10 Sky's @EdConwaySky explains the latest #C...      0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspects the Constraint validation set\n",
    "ct_val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fce7853f-44cd-43b4-9c40-48a0bd166d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Our daily update is published. States reported...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Alfalfa is the only cure for COVID-19.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>President Trump Asked What He Would Do If He W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>States reported 630 deaths. We are still seein...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>This is the sixth time a global health emergen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  label\n",
       "0   1  Our daily update is published. States reported...      0\n",
       "1   2             Alfalfa is the only cure for COVID-19.      1\n",
       "2   3  President Trump Asked What He Would Do If He W...      1\n",
       "3   4  States reported 630 deaths. We are still seein...      0\n",
       "4   5  This is the sixth time a global health emergen...      0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspects the Constraint test set\n",
    "ct_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "119d79b6-344b-46a9-80ac-4bde2ac99ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>politifact15164</td>\n",
       "      <td>Vice President Biden on Monday raised the poss...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politifact14394</td>\n",
       "      <td>Hillary Clinton had a third and most-likely fa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politifact3693</td>\n",
       "      <td>WASHINGTON, May 1, 2011 — -- AMANPOUR (voice-o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>politifact409</td>\n",
       "      <td>Nightly on MTV\\n\\nHost Rob Dyrdek is joined by...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>politifact4181</td>\n",
       "      <td>OMB HOME •\\n\\nHistorical Tables\\n\\nHistorical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                               text  label\n",
       "0  politifact15164  Vice President Biden on Monday raised the poss...      1\n",
       "1  politifact14394  Hillary Clinton had a third and most-likely fa...      1\n",
       "2   politifact3693  WASHINGTON, May 1, 2011 — -- AMANPOUR (voice-o...      0\n",
       "3    politifact409  Nightly on MTV\\n\\nHost Rob Dyrdek is joined by...      0\n",
       "4   politifact4181  OMB HOME •\\n\\nHistorical Tables\\n\\nHistorical ...      0"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drops the unwanted \"Unnamed\" column from the PolitiFact validation set\n",
    "pf_val_df = pf_val_df.drop(\"Unnamed: 0\", axis=1)\n",
    "pf_val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed91f1da-7fef-48d1-ab5c-df7e50c50416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>politifact15241</td>\n",
       "      <td>(Natural News) Late last month, it was reporte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politifact14794</td>\n",
       "      <td>ARE YOU READY? GET IT NOW!\\n\\nIncrease more th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politifact201</td>\n",
       "      <td>\"Some of the hardest-working and most producti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>politifact15207</td>\n",
       "      <td>Twitter Is Doing the MOST with These Cardi B G...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>politifact14727</td>\n",
       "      <td>New York City Woman Loses Her Temper, Causes B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                               text  label\n",
       "0  politifact15241  (Natural News) Late last month, it was reporte...      1\n",
       "1  politifact14794  ARE YOU READY? GET IT NOW!\\n\\nIncrease more th...      1\n",
       "2    politifact201  \"Some of the hardest-working and most producti...      0\n",
       "3  politifact15207  Twitter Is Doing the MOST with These Cardi B G...      1\n",
       "4  politifact14727  New York City Woman Loses Her Temper, Causes B...      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drops the unwanted \"Unnamed\" column from the PolitiFact test set\n",
    "pf_test_df = pf_test_df.drop(\"Unnamed: 0\", axis=1)\n",
    "pf_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7528cabd-b15b-4beb-a827-850084d1233e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gossipcop-867511</td>\n",
       "      <td>Andy Cohen Knows Exactly How to Push Vicki Gun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gossipcop-7946844362</td>\n",
       "      <td>Things are getting serious between Brad Pitt a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gossipcop-947390</td>\n",
       "      <td>Tuesday night might have made late-night histo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gossipcop-1500928748</td>\n",
       "      <td>Blake Shelton recently brought Gwen Stefani to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gossipcop-839877</td>\n",
       "      <td>Music festival season is right around the corn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               text  \\\n",
       "0      gossipcop-867511  Andy Cohen Knows Exactly How to Push Vicki Gun...   \n",
       "1  gossipcop-7946844362  Things are getting serious between Brad Pitt a...   \n",
       "2      gossipcop-947390  Tuesday night might have made late-night histo...   \n",
       "3  gossipcop-1500928748  Blake Shelton recently brought Gwen Stefani to...   \n",
       "4      gossipcop-839877  Music festival season is right around the corn...   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      1  \n",
       "2      0  \n",
       "3      1  \n",
       "4      0  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drops the unwanted \"Unnamed\" column from the GossipCop validation set\n",
    "gc_val_df = gc_val_df.drop(\"Unnamed: 0\", axis=1)\n",
    "gc_val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45cc1820-ce6b-4c79-9e66-9220b34849ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gossipcop-852394</td>\n",
       "      <td>— -- Last month, Elle King mysteriously posted...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gossipcop-892129</td>\n",
       "      <td>Roselyn Sanchez and Eric Winter have a new bun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gossipcop-938801</td>\n",
       "      <td>Will Smith is taking on the naysayers when it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gossipcop-941383</td>\n",
       "      <td>Don't let the name of's HBO hit fool you. Whil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gossipcop-6823819000</td>\n",
       "      <td>PALM BEACH, Fla. (AP) — President Donald Trump...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               text  \\\n",
       "0      gossipcop-852394  — -- Last month, Elle King mysteriously posted...   \n",
       "1      gossipcop-892129  Roselyn Sanchez and Eric Winter have a new bun...   \n",
       "2      gossipcop-938801  Will Smith is taking on the naysayers when it ...   \n",
       "3      gossipcop-941383  Don't let the name of's HBO hit fool you. Whil...   \n",
       "4  gossipcop-6823819000  PALM BEACH, Fla. (AP) — President Donald Trump...   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drops the unwanted \"Unnamed\" column from the GossipCop test set\n",
    "gc_test_df = gc_test_df.drop(\"Unnamed: 0\", axis=1)\n",
    "gc_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dc6c555-a399-4dd8-9951-916a7a31365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an all-four combined validation set\n",
    "all_val_data = createMixedDatasetForZeroShotScenario(\n",
    "    [wf_val_df, ct_val_df, pf_val_df, gc_val_df]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "753f06a2-df64-402c-aff5-ae65b5a696b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 'All four validation sets combined', 0 duplicate rows were removed.\n"
     ]
    }
   ],
   "source": [
    "# Drops duplicates from the all-four combined validation set\n",
    "all_val_data_no_duplicates = dropDuplicates(all_val_data, \"'All four validation sets combined'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "23007ad3-41b5-4084-bfea-51c40327e032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the all-four combined validation set as .csv file\n",
    "all_val_data.to_csv(\"../FPData/four_val_sets_combined.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffe54188-39da-4daf-bdcf-6944935a5d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an all-four combined validation set\n",
    "all_test_data = createMixedDatasetForZeroShotScenario(\n",
    "    [wf_test_df, ct_test_df, pf_test_df, gc_test_df]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79d2f0bd-3774-45f7-b0bf-f2adf9edf51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 'All four test sets combined', 1 duplicate rows were removed.\n"
     ]
    }
   ],
   "source": [
    "# Drops duplicates from the all-four combined test set\n",
    "all_test_data_no_duplicates = dropDuplicates(all_test_data, \"'All four test sets combined'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e7e9d5f1-d8de-489a-b30a-1f80c4f83db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the all-four combined test set as .csv file\n",
    "all_test_data_no_duplicates.to_csv(\"../../FPData/four_test_sets_combined.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
